{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebeb7b1-938f-499b-bdfa-819b67b33c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43bd5a09-101c-4a8e-9dd6-be8b448879be",
   "metadata": {},
   "source": [
    "# Webscraper with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12253df9-b7a3-4be6-abf1-39736672918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html2json\n",
    "import json\n",
    "from jsonpath_ng import jsonpath, parse\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from seleniumwire import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "class scraper:\n",
    "    def __init__(self, url):\n",
    "        self.url = 'https://www.ulta.com/shop/makeup/face'\n",
    "        self.json = {}\n",
    "\n",
    "    \n",
    "    def get_content(self):\n",
    "        r = requests.get(self.url)\n",
    "        return r.content\n",
    "    \n",
    "    def get_category(self):\n",
    "        r = requests.get(self.url)\n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "        content = soup.find_all(class_='CategoryCard')\n",
    "        categories = {}\n",
    "        for c in content:\n",
    "            category_tag = c.find('a', class_='Link_Huge')\n",
    "            category_name = category_tag.get_text()\n",
    "            category_link = category_tag.get('href')\n",
    "            self.json[category_name] = {}\n",
    "            self.json[category_name]['url'] = category_link\n",
    "            self.json[category_name]['products'] = []\n",
    "\n",
    "            get_product_links(category_link)\n",
    "        \n",
    "\n",
    "    \n",
    "    def get_product_links(self):\n",
    "        soup = BeautifulSoup(self.content, \"html.parser\")\n",
    "        content = soup.find_all(class_='ProductCard')\n",
    "        products = {}\n",
    "\n",
    "        for c in content:\n",
    "            product_link_tag = c.find('a', class_='Link_Huge Link_Huge--secondary')\n",
    "            product_link = product_link_tag.get('href')\n",
    "            self.json[category_name]['products'].append(product_link)\n",
    "            get_product_details(product_link)\n",
    "    \n",
    "    def get_product_details(product_link):\n",
    "        r = requests.get(product_link)\n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "        html_content = soup.find_all(class_='ProductHero__content')\n",
    "        details = ''\n",
    "\n",
    "        def extract_text_fields(json_data):\n",
    "            \"\"\"Extract all text fields using jsonpath-ng.\"\"\"\n",
    "            jsonpath_expression = parse('$.._value')\n",
    "            matches = jsonpath_expression.find(json_data)\n",
    "            return [match.value for match in matches]\n",
    "\n",
    "        def html_to_text_json(html_content):\n",
    "            \"\"\"Convert HTML content to a nested JSON containing only text fields.\"\"\"\n",
    "            json_data = html_to_json.convert(html_content)\n",
    "            text_fields = extract_text_fields(json_data)\n",
    "            #print(json.dumps(json_data, indent=4))\n",
    "            return text_fields\n",
    "        \n",
    "        # Convert HTML to text-only JSON\n",
    "        text_json = html_to_text_json(str(html_content))\n",
    "        \n",
    "        # Print the JSON output\n",
    "        #print(json.dumps(text_json, indent=4) )\n",
    "        details = ' '.join(text_json)\n",
    "        get_spec_product_details(product_link)\n",
    "        get_reviews(product_link)\n",
    "\n",
    "\n",
    "    def get_spec_prod_details(product_link): \n",
    "        r = requests.get(product_link)\n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "        content = soup.find_all(class_='ProductHero__content')\n",
    "    \n",
    "        for c in content:\n",
    "            name = c.find(class_= 'Text-ds Text-ds--body-1 Text-ds--left')\n",
    "            price = c.find(class_='ProductPricing')\n",
    "            id_num = c.find(class_='Text-ds Text-ds--body-3 Text-ds--left Text-ds--neutral-600')\n",
    "\n",
    "            product_price = price.get_text()\n",
    "            product_name = name.get_text()\n",
    "            product_id = id_num.get_text()\n",
    "\n",
    "            self.json[category_name]['products'] = {\n",
    "                'name': product_name,\n",
    "                'price': product_price,\n",
    "                'id': product_id\n",
    "            }\n",
    "    \n",
    "\n",
    "            \n",
    "    def get_product_reviews(product_link):\n",
    "        options = webdriver.ChromeOptions()\n",
    "        # Uncomment the following line to run in headless mode\n",
    "        #options.add_argument('--headless')\n",
    "        options.add_argument('--disable-gpu')\n",
    "        options.add_argument('--no-sandbox')\n",
    "        options.add_argument('--disable-dev-shm-usage')\n",
    "          \n",
    "        # Initialize the WebDriver\n",
    "        driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "        driver.maximize_window()\n",
    "        driver.get(product_link)\n",
    "        xhr_links = [] #stores the specific xhr links needed\n",
    "          \n",
    "        # Function to extract the XHR URL\n",
    "        def extract_xhr_url():\n",
    "            for request in driver.requests: \n",
    "                xhr_links.append(request.url)    \n",
    "         \n",
    "        # Define a function to gradually scroll through the entire page\n",
    "        def slow_scroll(start_position):\n",
    "            scroll_height = driver.execute_script('return document.body.scrollHeight')\n",
    "            current_position = start_position\n",
    "            while current_position < scroll_height:\n",
    "                driver.execute_script('window.scrollTo(0, {});'.format(current_position))\n",
    "                current_position += 100  # Adjust scrolling speed by changing increment\n",
    "                time.sleep(0.2)  # Adjust sleep time to control scrolling speed\n",
    "        \n",
    "        try:\n",
    "            # Wait for the section to be visible (adjust timeout as needed)\n",
    "            section_id = \"reviews\"\n",
    "            section_element = WebDriverWait(driver, 20).until(\n",
    "                EC.visibility_of_element_located((By.ID, section_id))\n",
    "            )\n",
    "            height =  0\n",
    "            time.sleep(2)\n",
    "            slow_scroll(height)\n",
    "            extract_xhr_url()\n",
    "        finally:\n",
    "            # Close the browser\n",
    "            driver.quit()\n",
    "            \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74528c38-be3a-44bd-9a7f-dd5ae62136e4",
   "metadata": {},
   "source": [
    "# Scratch Work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c452a4-eb38-47b7-87d3-063d7405a20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html_to_json\n",
    "import json\n",
    "from jsonpath_ng import jsonpath, parse\n",
    "\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from seleniumwire import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html_to_json\n",
    "import json\n",
    "from jsonpath_ng import jsonpath, parse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def get_category(link):\n",
    "    r = requests.get(link)\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    content = soup.find_all(class_='CategoryCard')\n",
    "    categories = {}\n",
    "    #print(content)\n",
    "    for c in content:\n",
    "        category_tag = c.find('a', class_='pal-c-Link pal-c-Link--primary pal-c-Link--default')\n",
    "        category_name = category_tag.get_text()\n",
    "        category_link = category_tag.get('href')\n",
    "        product_info[category_name] = {}\n",
    "        product_info[category_name]['url'] = category_link\n",
    "        product_info[category_name]['products'] = []\n",
    "        #print(category_link)\n",
    "        get_product_links(category_link, category_name)\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "def get_product_links(category_link, category_name):\n",
    "    r = requests.get(category_link)\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    content = soup.find_all(class_='ProductCard')\n",
    "    products = {}\n",
    "    products['name'] = category_name\n",
    "    products['url'] = category_link\n",
    "    products['product_list'] = []\n",
    "    \n",
    "    \n",
    "    for c in content:\n",
    "        product_link_tag = c.find('a', class_='pal-c-Link pal-c-Link--primary pal-c-Link--default')\n",
    "        product_link = product_link_tag.get('href')\n",
    "        product_info[category_name]['products'].append(product_link)\n",
    "        products['product_list'].append(get_product_details(product_link))\n",
    "    print(products)\n",
    "\n",
    "def get_product_details(product_link):\n",
    "    r = requests.get(product_link)\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    html_content = soup.find_all(class_='ProductHero__content')\n",
    "    details = ''\n",
    "    all_products = {}\n",
    "    all_products['url'] = product_link\n",
    "    def extract_text_fields(json_data):\n",
    "        jsonpath_expression = parse('$.._value')\n",
    "        matches = jsonpath_expression.find(json_data)\n",
    "        return [match.value for match in matches]\n",
    "\n",
    "        \n",
    "    def html_to_text_json(html_content):\n",
    "        \"\"\"Convert HTML content to a nested JSON containing only text fields.\"\"\"\n",
    "        json_data = html_to_json.convert(html_content)\n",
    "        text_fields = extract_text_fields(json_data)\n",
    "        #print(json.dumps(json_data, indent=4))\n",
    "        return text_fields\n",
    "    \n",
    "    # Convert HTML to text-only JSON\n",
    "    text_json = html_to_text_json(str(html_content))\n",
    "    \n",
    "    # Print the JSON output\n",
    "    #print(json.dumps(text_json, indent=4) )\n",
    "    details = ' '.join(text_json)\n",
    "    all_products['details'] = details\n",
    "    return all_products\n",
    "\n",
    "    #Next set of info to get\n",
    "    #get_spec_product_details(product_link)\n",
    "    #get_reviews(product_link)\n",
    "\n",
    "\n",
    "def get_spec_prod_details(product_link): \n",
    "    r = requests.get(product_link)\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    content = soup.find_all(class_='ProductHero__content')\n",
    "\n",
    "    for c in content:\n",
    "        name = c.find(class_= 'Text-ds Text-ds--body-1 Text-ds--left')\n",
    "        price = c.find(class_='ProductPricing')\n",
    "        id_num = c.find(class_='Text-ds Text-ds--body-3 Text-ds--left Text-ds--neutral-600')\n",
    "\n",
    "        product_price = price.get_text()\n",
    "        product_name = name.get_text()\n",
    "        product_id = id_num.get_text()\n",
    "\n",
    "        json[category_name]['products'] = {\n",
    "            'name': product_name,\n",
    "            'price': product_price,\n",
    "            'id': product_id\n",
    "        }\n",
    "        \n",
    "def get_product_reviews(product_link):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    # Uncomment the following line to run in headless mode\n",
    "    #options.add_argument('--headless')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "      \n",
    "    # Initialize the WebDriver\n",
    "    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "    driver.maximize_window()\n",
    "    driver.get(product_link)\n",
    "    xhr_links = [] #stores the specific xhr links needed\n",
    "      \n",
    "    # Function to extract the XHR URL\n",
    "    def extract_xhr_url():\n",
    "        for request in driver.requests: \n",
    "            xhr_links.append(request.url)    \n",
    "     \n",
    "    # Define a function to gradually scroll through the entire page\n",
    "    def slow_scroll(start_position):\n",
    "        scroll_height = driver.execute_script('return document.body.scrollHeight')\n",
    "        current_position = start_position\n",
    "        while current_position < scroll_height:\n",
    "            driver.execute_script('window.scrollTo(0, {});'.format(current_position))\n",
    "            current_position += 100  # Adjust scrolling speed by changing increment\n",
    "            time.sleep(0.2)  # Adjust sleep time to control scrolling speed\n",
    "    \n",
    "    try:\n",
    "        # Wait for the section to be visible (adjust timeout as needed)\n",
    "        section_id = \"reviews\"\n",
    "        section_element = WebDriverWait(driver, 20).until(\n",
    "            EC.visibility_of_element_located((By.ID, section_id))\n",
    "        )\n",
    "        height =  0\n",
    "        time.sleep(2)\n",
    "        slow_scroll(height)\n",
    "        extract_xhr_url()\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "url = 'https://www.ulta.com/shop/makeup/face'\n",
    "product_info = {}\n",
    "get_category(url) \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6594570-499f-4f6f-819b-7307f263735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html_to_json\n",
    "import json\n",
    "from jsonpath_ng import jsonpath, parse\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from seleniumwire import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "##Handle Pagination for Product Page to load more products\n",
    "##Have to click the load more button\n",
    "\n",
    "json = {}\n",
    "categories = {}\n",
    "ulta_link = 'https://www.ulta.com/shop/makeup/face'\n",
    "\n",
    "#Get all categories: \n",
    "def get_category(self):\n",
    "    r = requests.get(self.url)\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    content = soup.find_all(class_='CategoryCard')\n",
    "    categories = {}\n",
    "    for c in content:\n",
    "        category_tag = c.find('a', class_='Link_Huge')\n",
    "        category_name = category_tag.get_text()\n",
    "        category_link = category_tag.get('href')\n",
    "        categories[category_name] = {}\n",
    "        categories[category_name]['url'] = category_link\n",
    "        categories[category_name]['products'] = ['this ', 'is', 'SPARTA']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b054079e-2d7a-4a01-b3c2-ccd6c90c923d",
   "metadata": {},
   "source": [
    "## Extract Product Info to One String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f3c7ff-394e-4ff6-a00e-da34eff522fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html_to_json\n",
    "import json\n",
    "from jsonpath_ng import jsonpath, parse\n",
    "\n",
    "#<a class=\"Link_Huge Link_Huge--secondary\" target=\"_self\" href=\"https://www.ulta.com/p/double-wear-stay-in-place-foundation-xlsImpprod14641507?sku=2309420\"><div class=\"ProductCard__image ProductCard__image__full__small\"><div class=\"Image\"><img class=\"\" alt=\"Estée Lauder Double Wear Stay-in-Place Foundation\" aria-hidden=\"true\" loading=\"lazy\" width=\"360\" height=\"360\" src=\"https://media.ulta.com/i/ulta/2309420?w=360&amp;$ProductCardNeutralBGLight$&amp;fmt=auto\"></div><span class=\"ProductCard__variant\"><p class=\"Text-ds Text-ds--body-3 Text-ds--left Text-ds--neutral-600\">56 colors</p></span></div><div class=\"ProductCard__content\"><h3 class=\"ProductCard__heading\"><span class=\"ProductCard__brand\"><span class=\"Text-ds Text-ds--body-2 Text-ds--left Text-ds--neutral-600\">Estée Lauder</span></span><span class=\"ProductCard__product\"><span class=\"Text-ds Text-ds--body-2 Text-ds--left\">Double Wear Stay-in-Place Foundation</span></span></h3><div class=\"ProductCard__rating\"><div class=\"ReviewStarsCard\"><svg aria-hidden=\"true\" width=\"12\" height=\"12\"><path d=\"M5.999 1c.136 0 .262.076.324.198L7.81 4.144l2.862.284a.358.358 0 01.222.61L8.54 7.373l.873 3.172a.361.361 0 01-.31.452l-.051.002a.36.36 0 01-.15-.039L5.998 9.524 3.1 10.959a.361.361 0 01-.099.033l-.05.005a.361.361 0 01-.362-.454l.873-3.172-2.357-2.335a.358.358 0 01.222-.61l2.862-.284 1.485-2.944A.364.364 0 015.999 1z\" fill=\"currentColor\" fill-rule=\"nonzero\"></path></svg><svg aria-hidden=\"true\" width=\"12\" height=\"12\"><path d=\"M5.999 1c.136 0 .262.076.324.198L7.81 4.144l2.862.284a.358.358 0 01.222.61L8.54 7.373l.873 3.172a.361.361 0 01-.31.452l-.051.002a.36.36 0 01-.15-.039L5.998 9.524 3.1 10.959a.361.361 0 01-.099.033l-.05.005a.361.361 0 01-.362-.454l.873-3.172-2.357-2.335a.358.358 0 01.222-.61l2.862-.284 1.485-2.944A.364.364 0 015.999 1z\" fill=\"currentColor\" fill-rule=\"nonzero\"></path></svg><svg aria-hidden=\"true\" width=\"12\" height=\"12\"><path d=\"M5.999 1c.136 0 .262.076.324.198L7.81 4.144l2.862.284a.358.358 0 01.222.61L8.54 7.373l.873 3.172a.361.361 0 01-.31.452l-.051.002a.36.36 0 01-.15-.039L5.998 9.524 3.1 10.959a.361.361 0 01-.099.033l-.05.005a.361.361 0 01-.362-.454l.873-3.172-2.357-2.335a.358.358 0 01.222-.61l2.862-.284 1.485-2.944A.364.364 0 015.999 1z\" fill=\"currentColor\" fill-rule=\"nonzero\"></path></svg><svg aria-hidden=\"true\" width=\"12\" height=\"12\"><path d=\"M5.999 1c.136 0 .262.076.324.198L7.81 4.144l2.862.284a.358.358 0 01.222.61L8.54 7.373l.873 3.172a.361.361 0 01-.31.452l-.051.002a.36.36 0 01-.15-.039L5.998 9.524 3.1 10.959a.361.361 0 01-.099.033l-.05.005a.361.361 0 01-.362-.454l.873-3.172-2.357-2.335a.358.358 0 01.222-.61l2.862-.284 1.485-2.944A.364.364 0 015.999 1z\" fill=\"currentColor\" fill-rule=\"nonzero\"></path></svg><svg aria-hidden=\"true\" width=\"12\" height=\"12\"><path d=\"M2.712 10.917a.361.361 0 01-.122-.373l.388-1.41.483-1.762-2.355-2.334a.358.358 0 01.171-.603l.051-.008 2.862-.283L5.675 1.2a.364.364 0 01.274-.196L6.001 1v.002l.049.003a.364.364 0 01.273.195L7.81 4.146l2.862.283a.358.358 0 01.222.61L8.54 7.375l.873 3.172a.361.361 0 01-.511.416L6 9.525 3.103 10.96a.36.36 0 01-.391-.043zM6 2.041v6.817c.078 0 .156.015.23.042l.064.028 2.292 1.135-.69-2.512a.667.667 0 01.129-.602L8.07 6.9l1.889-1.873-2.215-.219a.667.667 0 01-.495-.304l-.034-.059z\" fill=\"currentColor\" fill-rule=\"nonzero\"></path></svg><span class=\"sr-only\">4.6 out of 5 stars ; 10645 reviews</span><span class=\"Text-ds Text-ds--body-3 Text-ds--left Text-ds--neutral-600\" aria-hidden=\"true\">(10,645)</span></div></div><div class=\"ProductCard__price\"><div class=\"ProductPricing\"><span class=\"Text-ds Text-ds--body-2 Text-ds--left Text-ds--black\">$52.00 </span></div></div><div class=\"ProductCard__offers\"><div><p class=\"Text-ds Text-ds--body-3 Text-ds--left Text-ds--magenta-500\">Bundle &amp; Save!</p></div></div></div></a>\n",
    "\n",
    "def get_product_links(): \n",
    "    r = requests.get(\"https://www.ulta.com/shop/makeup/face/foundation\")\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    content = soup.find_all(class_='ProductCard')\n",
    "    product_links = []\n",
    "    for c in content:\n",
    "        product_link_tag = c.find('a', class_='Link_Huge Link_Huge--secondary')\n",
    "        product_link = product_link_tag.get('href')\n",
    "        product_name = product_link_tag.get_text()\n",
    "        #print(product_name)\n",
    "        #print(product_link)\n",
    "\n",
    "        #print(get_product_details(product_link) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_text_fields(json_data):\n",
    "    \"\"\"Extract all text fields using jsonpath-ng.\"\"\"\n",
    "    jsonpath_expression = parse('$.._value')\n",
    "    matches = jsonpath_expression.find(json_data)\n",
    "    return [match.value for match in matches]\n",
    "\n",
    "def html_to_text_json(html_content):\n",
    "    \"\"\"Convert HTML content to a nested JSON containing only text fields.\"\"\"\n",
    "    json_data = html_to_json.convert(html_content)\n",
    "    text_fields = extract_text_fields(json_data)\n",
    "    #print(json.dumps(json_data, indent=4))\n",
    "    return text_fields\n",
    "\n",
    "# Example HTML content\n",
    "r = requests.get('https://www.ulta.com/p/double-wear-stay-in-place-foundation-xlsImpprod14641507?sku=2309420')\n",
    "soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "html_content =  soup.find_all(class_='ProductHero__content')\n",
    "#print(html_content)\n",
    "\n",
    "\n",
    "# Convert HTML to text-only JSON\n",
    "text_json = html_to_text_json(str(html_content))\n",
    "\n",
    "# Print the JSON output\n",
    "#print(json.dumps(text_json, indent=4) )\n",
    "print(' '.join(text_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70b3269-d19d-4c57-97ad-a32e88da242e",
   "metadata": {},
   "source": [
    "## Get Specific Product Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6680b85-e410-4873-80b0-06b62574cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html_to_json\n",
    "import json\n",
    "from jsonpath_ng import jsonpath, parse\n",
    "#pr_review\n",
    "def get_product_reviews(product_link):\n",
    "    r = requests.get('https://www.ulta.com/p/double-wear-stay-in-place-foundation-xlsImpprod14641507?sku=2309420')\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    content = soup.find_all(class_='ProductHero__content')\n",
    "    print(content)\n",
    "    reviews = []\n",
    " \n",
    "    for c in content:\n",
    "        name = c.find(class_= 'Text-ds Text-ds--body-1 Text-ds--left')\n",
    "        price = c.find(class_='ProductPricing')\n",
    "        id_num = c.find(class_='Text-ds Text-ds--body-3 Text-ds--left Text-ds--neutral-600')\n",
    "\n",
    "        review_content = soup.find_all(class_='reviews')\n",
    "\n",
    "\n",
    "        #product_link = product_link_tag.get('href')\n",
    "        product_price = price.get_text()\n",
    "        product_name = name.get_text()\n",
    "        product_id = id_num.get_text()\n",
    "        #print(product_name, product_price, product_id)\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "print( get_product_reviews('') )  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df54face-8d09-44dd-b00b-685779214be2",
   "metadata": {},
   "source": [
    "## Get Review Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332a9898-807b-4ae5-8c02-0216b0396527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html_to_json\n",
    "import json\n",
    "from jsonpath_ng import jsonpath, parse\n",
    "#pr_review\n",
    "\n",
    "\n",
    "def extract_text_fields(json_data):\n",
    "    \"\"\"Extract all text fields using jsonpath-ng.\"\"\"\n",
    "    jsonpath_expression = parse('$.._value')\n",
    "    matches = jsonpath_expression.find(json_data)\n",
    "    return [match.value for match in matches]\n",
    "\n",
    "def html_to_text_json(html_content):\n",
    "    \"\"\"Convert HTML content to a nested JSON containing only text fields.\"\"\"\n",
    "    json_data = html_to_json.convert(html_content)\n",
    "    text_fields = extract_text_fields(json_data)\n",
    "    #print(json.dumps(json_data, indent=4))\n",
    "    return text_fields\n",
    "\n",
    "\n",
    "# Example HTML content\n",
    "r = requests.get('https://www.ulta.com/p/double-wear-stay-in-place-foundation-xlsImpprod14641507?sku=2309420')\n",
    "soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "html_content =  soup.find_all(class_='ProductReviews__Content')\n",
    "#print(str(html_content))\n",
    "\n",
    "\n",
    "# Convert HTML to text-only JSON\n",
    "text_json = html_to_text_json(str(html_content))\n",
    "\n",
    "# Print the JSON output\n",
    "#print(json.dumps(text_json, indent=4) )\n",
    "print(text_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa1f896-90ac-4a49-b01c-82e93dd32471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html_to_json\n",
    "import json\n",
    "from jsonpath_ng import jsonpath, parse\n",
    "from requests_html import HTMLSession  \n",
    "import nest_asyncio\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "'''\n",
    "#&pr_rd_page=10\n",
    "r = requests.get('https://www.ulta.com/p/double-wear-stay-in-place-foundation-xlsImpprod14641507?sku=2309420&pr_rd_page=10')\n",
    "soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "html_content =  soup.find_all(class_='ProductReviews__Content')\n",
    "print(html_content)\n",
    "'''\n",
    "url = 'https://www.ulta.com/p/double-wear-stay-in-place-foundation-xlsImpprod14641507?sku=2309420'\n",
    "# Setup WebDriver\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "driver.get('file://' + 'temp.html')\n",
    "\n",
    "\n",
    "with open('temp.html', 'w') as file:\n",
    "    file.write(html_content)\n",
    "\n",
    "# Extract the JavaScript code from a specific part of the HTML\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "content_div = soup.find('div', {'id': 'content'})\n",
    "scripts = content_div.find_all('script')\n",
    "\n",
    "javascript_code = []\n",
    "for script in scripts:\n",
    "    if script.string:\n",
    "        javascript_code.append(script.string.strip())\n",
    "\n",
    "# Execute the JavaScript code\n",
    "for js in javascript_code:\n",
    "    driver.execute_script(js)\n",
    "\n",
    "# Optionally, print the result of JavaScript execution\n",
    "result = driver.find_element_by_id('result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb5568d-f34c-4569-b363-daf2e944fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "#from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "\n",
    "# Set up Chrome options\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')  # Run in headless mode (no GUI)\n",
    "options.add_argument('--disable-gpu')  # Disable GPU hardware acceleration\n",
    "options.add_argument('--no-sandbox')  # Bypass OS security model\n",
    "\n",
    "# Initialize the WebDriver\n",
    "service = ChromeService(executable_path=ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "# Define a wait time\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "try:\n",
    "    # Wait for the product heading to be present\n",
    "    product_heading = wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'ProductReviews__Content')))\n",
    "    print(product_heading.text)\n",
    "\n",
    "    # If you need to extract reviews, wait for the review section to be present\n",
    "    reviews = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, 'p-w-r')))\n",
    "    for review in reviews:\n",
    "        print(review.text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a623af0-f22f-4d8b-b16b-d06c8de7ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Set up Chrome options\n",
    "options = webdriver.ChromeOptions()\n",
    "# Uncomment the following line to run in headless mode\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "try:\n",
    "    # Open the URL\n",
    "    url = \"https://www.ulta.com/p/double-wear-stay-in-place-foundation-xlsImpprod14641507?sku=2309420\"\n",
    "    driver.get(url)\n",
    "\n",
    "    # Print the title of the page to verify it worked\n",
    "    print(driver.title)\n",
    "    \n",
    "    # Wait for the reviews section to load\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    # Find and print reviews\n",
    "    reviews = driver.find_elements(By.CLASS_NAME, \"ProductReviews__Reviews--containerList\")\n",
    "    for review in reviews:\n",
    "        print(review.text)\n",
    "        print(review.text, \"works\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Close the WebDriver\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29247e7-c62c-45a5-8db6-b3b6d2f0a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Set up Chrome options\n",
    "options = webdriver.ChromeOptions()\n",
    "# Uncomment the following line to run in headless mode\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "\n",
    "# Navigate to the Ulta product page\n",
    "driver.get(\"https://www.ulta.com/p/double-wear-stay-in-place-foundation-xlsImpprod14641507?sku=2309420\")\n",
    "\n",
    "# Define variables for pagination\n",
    "current_page = 1\n",
    "max_pages = 5  # Example: scrape up to 5 pages\n",
    "\n",
    "#review_elements = driver.find_element('xpath', \"//div[contains(@class, 'ProductReviews__Reviews--containerList')]\")\n",
    "#print(review_elements) \n",
    "articleDictionary = dict()\n",
    "myKey = \"\"\n",
    "myValue_total = \"\"\n",
    "\n",
    "# Optionally wait for the page to load completely\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//div[@class='ProductReviews__Reviews--containerList']\")))\n",
    "\n",
    "# Get the HTML content\n",
    "html_content = driver.page_source\n",
    "print(html_content) \n",
    "\n",
    "\n",
    "while current_page <= max_pages:\n",
    "    # Scrape data from the current page\n",
    "    review_elements = driver.find_elements('xpath', \"//div[contains(@class, 'ProductReviews')]\")\n",
    "    #print(review.get_attribute(\"innerText\"))\n",
    "    \n",
    "    #scripts = driver.execute_script()\n",
    "    \n",
    "    for review in review_elements:\n",
    "        #print(review.tag_name)\n",
    "        #print('NEW LINE')\n",
    "        '''\n",
    "        # Extract review information\n",
    "        #rating = review.find_element_by_xpath(\".//div[contains(@class, 'Rating')]//svg\").get_attribute(\"aria-label\").strip()\n",
    "        review_text = review.find_element('xpath', \".//div[contains(@class, 'p-w-r')]\").text.strip()\n",
    "        \n",
    "        # Process the data (print for now)\n",
    "        #print(f\"Rating: {rating}\")\n",
    "        print(f\"Review Text: {review_text}\")\n",
    "        print(\"-\" * 50)\n",
    "        '''\n",
    "    \n",
    "    \n",
    "    # Navigate to the next page if available\n",
    "    try:\n",
    "        next_button = driver.find_element('xpath',\"//a[contains(@class, 'pr-rd-pagination')]\")\n",
    "        if next_button:\n",
    "            next_button.click()\n",
    "            current_page += 1\n",
    "            time.sleep(2)  # Add a short delay to ensure the next page loads completely\n",
    "    except NoSuchElementException:\n",
    "        break  # Exit loop if no next page link found or reached max pages\n",
    "\n",
    "# Close the WebDriver session\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fdf5ea-da05-43df-9f66-4f32b812f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html_to_json\n",
    "import json\n",
    "from jsonpath_ng import jsonpath, parse\n",
    "\n",
    "# Load the HTML content from a file\n",
    "r = requests.get(\"https://www.ulta.com/p/double-wear-stay-in-place-foundation-xlsImpprod14641507?sku=2309420\")\n",
    "\n",
    "\n",
    "# Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "# Specify the class name of the div you want to extract information from\n",
    "target_class = 'p-w-r'\n",
    "\n",
    "# Find all div elements with the specified class\n",
    "div_elements = soup.find_all('div', class_=target_class)\n",
    "print(div_elements)\n",
    "\n",
    "# Extract the desired information from each div element\n",
    "for index, div in enumerate(div_elements):\n",
    "    # Extract text content of the div\n",
    "    div_text = div.get_text(strip=True)\n",
    "    print(f\"Div {index + 1} text:\\n{div_text}\\n\")\n",
    "    \n",
    "    # Extract other specific elements or attributes within the div if needed\n",
    "    # Example: Extract all href attributes of <a> tags within the div\n",
    "    '''\n",
    "    links = div.find_all('a')\n",
    "    for link in links:\n",
    "        print(f\"Link: {link['href']}\")\n",
    "    '''\n",
    "'''\n",
    "# Optionally, you can write the extracted information to a file\n",
    "with open('extracted_div_content.txt', 'w', encoding='utf-8') as file:\n",
    "    for div in div_elements:\n",
    "        div_text = div.get_text(strip=True)\n",
    "        file.write(f\"Div text:\\n{div_text}\\n\\n\")\n",
    "        links = div.find_all('a')\n",
    "        for link in links:\n",
    "            file.write(f\"Link: {link['href']}\\n\")\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a3e57b-8a5b-4cd3-8bd8-08cc63645221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Load the HTML content from a file\n",
    "with open('page_source.html', 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find all script tags\n",
    "script_tags = soup.find_all('script')\n",
    "\n",
    "# Extract the JavaScript code from each script tag\n",
    "javascript_code = []\n",
    "for script in script_tags:\n",
    "    if script.string:\n",
    "        javascript_code.append(script.string)\n",
    "\n",
    "# Print all JavaScript code found\n",
    "for index, code in enumerate(javascript_code):\n",
    "    print(f\"JavaScript code {index + 1}:\\n{code}\\n\")\n",
    "\n",
    "'''\n",
    "# Optionally, you can write the JavaScript code to a file\n",
    "with open('extracted_javascript.js', 'w', encoding='utf-8') as file:\n",
    "    for code in javascript_code:\n",
    "        file.write(code + '\\n\\n')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f666698d-a3bb-4c65-a0c8-487a9bf4237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html_to_json\n",
    "import json\n",
    "from jsonpath_ng import jsonpath, parse\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "# Set up ChromeOptions\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run Chrome in headless mode\n",
    "chrome_options.add_argument('--disable-gpu')  # Disable GPU acceleration (often needed in headless mode)\n",
    "# Set up Chrome WebDriver (make sure chromedriver is in your PATH)\n",
    "driver = webdriver.Chrome(chrome_options)\n",
    "\n",
    "\n",
    "# Load the HTML content from a file\n",
    "driver.get(\"https://www.ulta.com/p/double-wear-stay-in-place-foundation-xlsImpprod14641507?sku=2309420&pr_rd_page=2\")\n",
    "# Wait for pr-review elements to be present\n",
    "\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.CLASS_NAME, \"ProductReviews__Reviews--containerList\"))\n",
    ")\n",
    "\n",
    "# Wait for the pagination link to be clickable\n",
    "next_page_link = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.CSS_SELECTOR, 'div.pr-rd-pagination a.pr-rd-pagination-btn--next'))\n",
    ")\n",
    "\n",
    "# Click the pagination link to load more content\n",
    "next_page_link.click()\n",
    "\n",
    "try:\n",
    "    pr_reviews = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.CLASS_NAME, \"pr-review\"))\n",
    "    )\n",
    "\n",
    "    print(\"got reviews\")\n",
    "finally:\n",
    "    # Get the initial text content of the first pr-review element\n",
    "    print([pr_review.text for pr_review in pr_reviews])\n",
    "\n",
    "# Wait until the text content of pr-review elements changes\n",
    "WebDriverWait(driver, 10).until(\n",
    "    lambda driver: EC.text_to_be_present_in_element((By.CLASS_NAME, \"pr-review\"), initial_text)(driver) is False\n",
    ")\n",
    "file_path = \"webtext_page2_with_seleniumv2.json\"\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(str(driver.page_source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d03f4a-54bd-4d80-8b8d-6ffff7414722",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from seleniumwire import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Set up Chrome options\n",
    "options = webdriver.ChromeOptions()\n",
    "# Uncomment the following line to run in headless mode\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Function to extract the XHR URL\n",
    "def extract_xhr_url(url):\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait until the desired network request is made\n",
    "    def wait_for_xhr_request(driver):\n",
    "        for request in driver.requests:\n",
    "            if request.response and 'displaypowerreviews' in request.url:\n",
    "                return request.url\n",
    "        return False\n",
    "\n",
    "    # WebDriverWait to wait for the XHR request\n",
    "    xhr_url = WebDriverWait(driver, 100).until(wait_for_xhr_request)\n",
    "    print('XHR URL:', xhr_url)\n",
    "\n",
    "# Example URL of a product page on Ulta\n",
    "product_url = 'https://www.ulta.com/p/double-wear-stay-in-place-foundation-xlsImpprod14641507?sku=2309420'\n",
    "extract_xhr_url(product_url)\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706699e3-7e53-44c1-b040-96113d71688c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from seleniumwire import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "# Set up Chrome options\n",
    "options = webdriver.ChromeOptions()\n",
    "# Uncomment the following line to run in headless mode\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Function to extract the XHR URL\n",
    "def extract_xhr_url(url):\n",
    "    driver.get(url)\n",
    "\n",
    "     # Wait for XHR request that contains 'reviews' in URL\n",
    "    reviews_request = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"ProductReviews__Reviews--containerList\"))\n",
    "    )\n",
    "        \n",
    "    with open('get_requests.txt', 'w', encoding='utf-8') as file:\n",
    "        for request in driver.requests:\n",
    "            file.write(request.url + '\\n\\n')\n",
    "    # Loop to wait for the XHR request indefinitely\n",
    "    #xhr_url =  reviews_request.path\n",
    "\n",
    "    #print('XHR URL:', xhr_url)\n",
    "\n",
    "# Example URL of a product page on Ulta\n",
    "product_url = 'https://www.ulta.com/p/double-wear-stay-in-place-foundation-xlsImpprod14641507?sku=2309420'\n",
    "extract_xhr_url(product_url)\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfd78ac-2d0f-482d-9bdd-663095478d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from seleniumwire import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "\n",
    "# Set up Chrome options\n",
    "options = webdriver.ChromeOptions()\n",
    "# Uncomment the following line to run in headless mode\n",
    "#options.add_argument('--headless')\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "driver.get('https://www.ulta.com/p/double-wear-stay-in-place-foundation-xlsImpprod14641507?sku=2309420')\n",
    "\n",
    "# Function to scroll down\n",
    "def scroll_down(driver):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    print('def scroll_down')\n",
    "\n",
    "def have_reviews():\n",
    "    #actions = ActionChains(driver)\n",
    "    #actions.move_to_element(element).perform()\n",
    "    print('found the element!')\n",
    "    return any(['display.powerreviews' in request.url for request in driver.requests])\n",
    "\n",
    "# Scroll down and load more content\n",
    "while not have_reviews():\n",
    "    scroll_down(driver)\n",
    "    \n",
    "\n",
    "# Function to extract the XHR URL\n",
    "def extract_xhr_url():\n",
    "    with open('get_requests.txt', 'w', encoding='utf-8') as file:\n",
    "        for request in driver.requests:\n",
    "            file.write(request.url + '\\n\\n')\n",
    "# Close the WebDriver\n",
    "extract_xhr_url()\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab6d38-0194-4dac-bf84-1c8dcc7e2099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from seleniumwire import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "\n",
    "# Set up Chrome options\n",
    "options = webdriver.ChromeOptions()\n",
    "# Uncomment the following line to run in headless mode\n",
    "#options.add_argument('--headless')\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "driver.get('https://www.ulta.com/p/double-wear-stay-in-place-foundation-xlsImpprod14641507?sku=2309420')\n",
    "section_locator = (By.ID, \"reviews\")\n",
    "print(selection_locator)\n",
    "\n",
    "# Wait for the section to be visible\n",
    "section_element = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_element_located(section_locator)\n",
    ")\n",
    "# Scroll to the specific section\n",
    "driver.execute_script(\"arguments[0].scrollIntoView();\", section_element)\n",
    "\n",
    "# Function to check if at bottom of the page\n",
    "def is_at_bottom():\n",
    "    # Implement logic to check if at the bottom\n",
    "    return driver.execute_script(\"return (window.innerHeight + window.scrollY) >= document.body.offsetHeight\")\n",
    "\n",
    "\n",
    "\n",
    "# Function to extract the XHR URL\n",
    "def extract_xhr_url():\n",
    "    with open('zara_request.txt', 'w', encoding='utf-8') as file:\n",
    "        for request in driver.requests:\n",
    "            file.write(request.url + '\\n\\n')\n",
    "\n",
    "# Scroll down to the bottom of the page\n",
    "while not is_at_bottom():\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        lambda driver: driver.execute_script('return document.readyState') == 'complete')\n",
    "\n",
    "# Close the WebDriver\n",
    "extract_xhr_url()\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01b8ef3-8f85-4f72-b96a-d58e8273242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from seleniumwire import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "\n",
    "# Set up Chrome options\n",
    "options = webdriver.ChromeOptions()\n",
    "# Uncomment the following line to run in headless mode\n",
    "#options.add_argument('--headless')\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "driver.get('https://www.ulta.com/p/double-wear-stay-in-place-foundation-xlsImpprod14641507?sku=2309420')\n",
    "\n",
    "def load():\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    WebDriverWait(driver, 30).until(\n",
    "        lambda driver: driver.execute_script('return document.readyState') == 'complete' )\n",
    "\n",
    "# Function to extract the XHR URL\n",
    "def extract_xhr_url():\n",
    "    with open('zara_request.txt', 'w', encoding='utf-8') as file:\n",
    "        for request in driver.requests:\n",
    "            file.write(request.url + '\\n\\n')\n",
    "\n",
    "# Function to check if at bottom of the page\n",
    "def is_at_bottom():\n",
    "    # Slow scroll to the section\n",
    "    scroll_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    current_position = 0\n",
    "    while current_position < scroll_height:\n",
    "        driver.execute_script('window.scrollTo(0, {});'.format(current_position))\n",
    "        current_position += 100  # Adjust scrolling speed by changing increment\n",
    "        time.sleep(0.1)  # Adjust sleep time to control scrolling speed\n",
    "\n",
    "    # Pause for a few seconds to observe the section\n",
    "    time.sleep(10)  # Adjust as needed\n",
    "\n",
    "# Function to extract the XHR URL\n",
    "def extract_xhr_url():\n",
    "    with open('zara_request.txt', 'w', encoding='utf-8') as file:\n",
    "        for request in driver.requests:\n",
    "            file.write(request.url + '\\n\\n')\n",
    "\n",
    "load()\n",
    "\n",
    "try:\n",
    "    section_id = \"reviews\"\n",
    "    section_element = WebDriverWait(driver, 10).until(\n",
    "        EC.visibility_of_element_located((By.ID, section_id))\n",
    "    )\n",
    "\n",
    "    # Scroll to the section using scrollIntoView\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView({ block: 'center', inline: 'center' });\", section_element)\n",
    "\n",
    "    # Pause for a few seconds to observe the section\n",
    "    scroll_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    current_position = 0\n",
    "    while current_position < scroll_height:\n",
    "        driver.execute_script('window.scrollTo(0, {});'.format(current_position))\n",
    "        current_position += 100  # Adjust scrolling speed by changing increment\n",
    "        time.sleep(0.2)  # Adjust sleep time to control scrolling speed\n",
    "    extract_xhr_url()\n",
    "    time.sleep(5)\n",
    "\n",
    "    \n",
    "#time.sleep(5)  # Adjust as needed\n",
    "\n",
    "finally:\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "'''\n",
    "    # Pause for a few seconds to observe the section\n",
    "    time.sleep(5)  # Adjust as needed\n",
    "    # Scroll down to the bottom of the page\n",
    "    while not is_at_bottom():\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        WebDriverWait(driver, 15).until(\n",
    "            lambda driver: driver.execute_script('return document.readyState') == 'complete')\n",
    "        \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58688bba-8f18-4db1-a035-d195b7db064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from seleniumwire import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "#import logging\n",
    "\n",
    "# Set up Chrome options\n",
    "options = webdriver.ChromeOptions()\n",
    "# Uncomment the following line to run in headless mode\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "#options.add_argument('--headless')\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "#options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "driver.maximize_window()\n",
    "driver.get('https://www.ulta.com/p/double-wear-stay-in-place-foundation-xlsImpprod14641507?sku=2309420')\n",
    "xhr_links = [] #stores the specific xhr links needed\n",
    "\n",
    "\n",
    "# Function to extract the XHR URL\n",
    "def extract_xhr_url():\n",
    "    for request in driver.requests: \n",
    "        xhr_links.append(request.url)\n",
    "\n",
    " \n",
    "# Define a function to gradually scroll through the entire page\n",
    "def slow_scroll(start_position):\n",
    "    scroll_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    current_position = start_position\n",
    "    while current_position < scroll_height:\n",
    "        driver.execute_script('window.scrollTo(0, {});'.format(current_position))\n",
    "        current_position += 100  # Adjust scrolling speed by changing increment\n",
    "        time.sleep(0.2)  # Adjust sleep time to control scrolling speed\n",
    "\n",
    "try:\n",
    "    # Wait for the section to be visible (adjust timeout as needed)\n",
    "    section_id = \"reviews\"\n",
    "    section_element = WebDriverWait(driver, 20).until(\n",
    "        EC.visibility_of_element_located((By.ID, section_id))\n",
    "    )\n",
    "    height =  0\n",
    "    time.sleep(2)\n",
    "    slow_scroll(height)\n",
    "    extract_xhr_url()\n",
    "finally:\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "for x in xhr_links: \n",
    "    if 'display.powerreviews' in x: \n",
    "        print(x, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4736cc8-330e-4af5-ace9-a54c0f26d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from seleniumwire import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "# Set up Chrome options\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "driver.maximize_window()\n",
    "driver.get('https://www.ulta.com/p/double-wear-stay-in-place-foundation-xlsImpprod14641507?sku=2309420')\n",
    "xhr_links = []  # Stores the specific xhr links needed\n",
    "\n",
    "# Function to extract the XHR URL\n",
    "def extract_xhr_url():\n",
    "    for request in driver.requests:\n",
    "        xhr_links.append(request.url)\n",
    "\n",
    "# Define a function to gradually scroll through the entire page\n",
    "def slow_scroll(start_position):\n",
    "    scroll_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    current_position = start_position\n",
    "    while current_position < scroll_height:\n",
    "        driver.execute_script('window.scrollTo(0, {});'.format(current_position))\n",
    "        current_position += 100  # Adjust scrolling speed by changing increment\n",
    "        time.sleep(0.2)  # Adjust sleep time to control scrolling speed\n",
    "\n",
    "# Function to click the \"Next\" link\n",
    "def click_next_page():\n",
    "    try:\n",
    "        next_page_link = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CLASS_NAME, 'pr-rd-pagination-btn--next'))\n",
    "        )\n",
    "        try:\n",
    "            next_page_link.click()\n",
    "        except ElementClickInterceptedException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_link)\n",
    "        return True\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "\n",
    "try:\n",
    "    # Wait for the section to be visible (adjust timeout as needed)\n",
    "    section_id = \"reviews\"\n",
    "    section_element = WebDriverWait(driver, 20).until(\n",
    "        EC.visibility_of_element_located((By.ID, section_id))\n",
    "    )\n",
    "    height = section_element.location['y']\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Scroll to the reviews section\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView({ behavior: 'instant', block: 'start' });\", section_element)\n",
    "    \n",
    "    # Start the slow scroll from the reviews section\n",
    "    slow_scroll(height)\n",
    "    \n",
    "    # Extract initial XHR URLs\n",
    "    extract_xhr_url()\n",
    "    \n",
    "    # Click the \"Next\" link and scroll again\n",
    "    pg_count = 1\n",
    "    while click_next_page() and pg_count < 2:\n",
    "        pg_count += 1\n",
    "        time.sleep(2)  # Wait for new content to load\n",
    "        slow_scroll(height)\n",
    "        extract_xhr_url()\n",
    "\n",
    "finally:\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "# Print the extracted XHR URLs\n",
    "for x in xhr_links: \n",
    "    if 'display.powerreviews' in x: \n",
    "        print(x, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c434f5-82b1-40bd-aa17-a1011ca2ff36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
